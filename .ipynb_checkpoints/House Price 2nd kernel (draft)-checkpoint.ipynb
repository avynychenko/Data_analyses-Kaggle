{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!!! Для чекинга учеников - засабмитить препроцессинг с align, но заполнить пропуски импутером со средним - дает лучший результат скоров\n",
    "\n",
    "n_estimators = 450, learning_rate= 0.065, colsample_bytree = 0.8, subsample = 0.8, max_depth = 4, reg_lambda = 0.998\n",
    "\n",
    "\n",
    "Mean Absolute Error: 14642.478502247432\n",
    "\n",
    "Root Mean Squared Error: 0.12153794263233741\n",
    "\n",
    "Root Mean Squared Error: 29848.361709034547\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "X = pd.read_csv('/Users/avyny/Documents/Data_analyses-Kaggle/Data_House_Pricing/train.csv', index_col='Id')\n",
    "X_test_full = pd.read_csv('/Users/avyny/Documents/Data_analyses-Kaggle/Data_House_Pricing/test.csv', index_col='Id')\n",
    "# X = pd.read_csv('D:\\\\Learning_IT\\\\Data_analyses-Kaggle\\\\Data_House_Pricing\\\\train.csv', index_col='Id')\n",
    "# X_test_full = pd.read_csv('D:\\\\Learning_IT\\\\Data_analyses-Kaggle\\\\Data_House_Pricing\\\\test.csv', index_col='Id')\n",
    "\n",
    "y = X.SalePrice              \n",
    "X.drop(['SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "X = X.drop(['Alley', 'PoolQC','Fence','MiscFeature', 'Utilities', 'Street', 'PoolArea', 'MiscVal'], axis=1)\n",
    "X_test_full = X_test_full.drop(['Alley', 'PoolQC','Fence','MiscFeature', 'Utilities', 'Street', 'PoolArea', 'MiscVal'], axis=1)\n",
    "\n",
    "# Break off validation set from training data\n",
    "X_train_full, X_valid_full, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)\n",
    "\n",
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "# low_cardinality_cols = [cname for cname in X_train_full.columns if X_train_full[cname].nunique() < 10 and \n",
    "#                         X_train_full[cname].dtype == \"object\"]\n",
    "# low_cardinality_cols = [cname for cname in X_train_full.columns if X_train_full[cname].dtype == \"object\"]\n",
    "\n",
    "# # Select numeric columns\n",
    "# numeric_cols = [cname for cname in X_train_full.columns if X_train_full[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "# # Keep selected columns only\n",
    "# my_cols = low_cardinality_cols + numeric_cols\n",
    "# X_train = X_train_full[my_cols].copy()\n",
    "# X_valid = X_valid_full[my_cols].copy()\n",
    "# X_test = X_test_full[my_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get_dummies () without filling NA\n",
    "\n",
    "# One-hot encode the data (to shorten the code, we use pandas)\n",
    "# X_train = pd.get_dummies(X_train)\n",
    "# X_valid = pd.get_dummies(X_valid)\n",
    "# X_test = pd.get_dummies(X_test)\n",
    "# X_train, X_valid = X_train.align(X_valid, join='left', axis=1)\n",
    "# X_train, X_test = X_train.align(X_test, join='left', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [cname for cname in X.columns if X[cname].dtype == \"object\"]\n",
    "# categorical_cols = [cname for cname in X.columns if X[cname].nunique() < 10 and \n",
    "#                         X[cname].dtype == \"object\"]\n",
    "numerical_median = ['OverallCond', 'OverallQual', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2',\n",
    "                   'BsmtUnfSF', 'LowQualFinSF', 'GrLivArea', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr',\n",
    "                   'TotRmsAbvGrd', 'GarageYrBlt', 'GarageCars', 'EnclosedPorch', 'ScreenPorch', 'MoSold', 'YrSold'\n",
    "                   ]\n",
    "\n",
    "numerical_mean = ['LotFrontage', 'LotArea', '1stFlrSF', '2ndFlrSF', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF']\n",
    "\n",
    "numerical_frequent = ['MSSubClass', 'BsmtFullBath', 'BsmtHalfBath', 'Fireplaces']\n",
    "\n",
    "all_cols = numerical_median + numerical_mean + numerical_frequent + categorical_cols\n",
    "\n",
    "X_train = X_train_full[all_cols].copy()\n",
    "X_valid = X_valid_full[all_cols].copy()\n",
    "X_test = X_test_full[all_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical_transformer_mean = SimpleImputer(strategy='mean')\n",
    "# numerical_transformer_median = SimpleImputer(strategy='median')\n",
    "# numerical_transformer_freq = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# categorical_transformer = Pipeline(steps=[\n",
    "#     ('imputer', SimpleImputer(strategy='most_frequent'))\n",
    "# ])\n",
    "\n",
    "# preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         ('num1', numerical_transformer_mean, numerical_mean),\n",
    "#         ('num2', numerical_transformer_median, numerical_median),\n",
    "#         ('num3', numerical_transformer_freq, numerical_frequent),\n",
    "#         ('cat', categorical_transformer, categorical_cols)\n",
    "#     ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train1 = pd.DataFrame(preprocessor.fit_transform(X_train))\n",
    "# X_train1.columns = numerical_mean + numerical_median + numerical_frequent + categorical_cols\n",
    "# X_train1[numerical_median + numerical_mean + numerical_frequent] = X_train1[numerical_median + numerical_mean + numerical_frequent].apply(pd.to_numeric) \n",
    "# X_train1 = pd.get_dummies(X_train1)\n",
    "# # X_train.head() # 263\n",
    "\n",
    "# X_valid1 = pd.DataFrame(preprocessor.fit_transform(X_valid))\n",
    "# X_valid1.columns = numerical_mean + numerical_median + numerical_frequent + categorical_cols\n",
    "# X_valid1[numerical_median + numerical_mean + numerical_frequent] = X_valid1[numerical_median + numerical_mean + numerical_frequent].apply(pd.to_numeric) \n",
    "# X_valid1 = pd.get_dummies(X_valid1)\n",
    "# # X_valid.head() # 239\n",
    "\n",
    "# X_test1 = pd.DataFrame(preprocessor.fit_transform(X_test))\n",
    "# X_test1.columns = numerical_mean + numerical_median + numerical_frequent + categorical_cols\n",
    "# X_test1[numerical_median + numerical_mean + numerical_frequent] = X_test1[numerical_median + numerical_mean + numerical_frequent].apply(pd.to_numeric) \n",
    "# X_test1 = pd.get_dummies(X_test1)\n",
    "# X_test1.index = X_test_full.index\n",
    "# # X_test.head() # 252\n",
    "\n",
    "# X_train1, X_valid1 = X_train1.align(X_valid1, join='left', axis=1)\n",
    "# X_train1, X_test1 = X_train1.align(X_test1, join='left', axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### PART WITH SIMPLE IMMPUTER - ONE FOR ALL\n",
    "\n",
    "X_train = pd.get_dummies(X_train)\n",
    "X_valid = pd.get_dummies(X_valid)\n",
    "X_test = pd.get_dummies(X_test)\n",
    "\n",
    "si = SimpleImputer(strategy='mean')\n",
    "\n",
    "X_train1 = pd.DataFrame(si.fit_transform(X_train))\n",
    "X_train1.columns = X_train.columns\n",
    "\n",
    "X_valid1 = pd.DataFrame(si.fit_transform(X_valid))\n",
    "X_valid1.columns = X_valid.columns\n",
    "\n",
    "X_test1 = pd.DataFrame(si.fit_transform(X_test))\n",
    "X_test1.columns = X_test.columns\n",
    "X_test1.index = X_test.index\n",
    "\n",
    "X_train1, X_valid1 = X_train1.align(X_valid1, join='left', axis=1)\n",
    "X_train1, X_test1 = X_train1.align(X_test1, join='left', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:21:17] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=0.8, gamma=0,\n",
       "             importance_type='gain', learning_rate=0.065, max_delta_step=0,\n",
       "             max_depth=4, min_child_weight=1, missing=None, n_estimators=450,\n",
       "             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "             reg_alpha=0, reg_lambda=0.998, scale_pos_weight=1, seed=None,\n",
       "             silent=None, subsample=0.8, verbosity=1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model_2 = XGBRegressor(n_estimators = 450, learning_rate= 0.065, colsample_bytree = 0.8, subsample = 0.8, max_depth = 4, reg_lambda = 0.998)\n",
    "# my_model_2 = XGBRegressor(n_estimators = 900, learning_rate= 0.04, subsample = 0.8)\n",
    "\n",
    "# Fit the model\n",
    "my_model_2.fit(X_train1, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Detecting of feature importance***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.186780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.121367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>169</td>\n",
       "      <td>0.116161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>157</td>\n",
       "      <td>0.060454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.045665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>244</td>\n",
       "      <td>0.026188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.025880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       x         y\n",
       "16    16  0.186780\n",
       "1      1  0.121367\n",
       "169  169  0.116161\n",
       "157  157  0.060454\n",
       "10    10  0.045665\n",
       "244  244  0.026188\n",
       "9      9  0.025880"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'x': range(0, 263), 'y': my_model_2.feature_importances_}).sort_values(by = 'y', ascending = False).head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>BsmtQual_Ex</th>\n",
       "      <th>ExterQual_TA</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>GarageCond_TA</th>\n",
       "      <th>GrLivArea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1828.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>894.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>964.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1689.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1541.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GarageCars  OverallQual  BsmtQual_Ex  ExterQual_TA  FullBath  \\\n",
       "0         3.0          9.0          1.0           0.0       2.0   \n",
       "1         1.0          5.0          0.0           1.0       1.0   \n",
       "2         2.0          5.0          0.0           1.0       1.0   \n",
       "3         3.0          8.0          0.0           0.0       2.0   \n",
       "4         3.0          7.0          0.0           0.0       2.0   \n",
       "\n",
       "   GarageCond_TA  GrLivArea  \n",
       "0            1.0     1828.0  \n",
       "1            1.0      894.0  \n",
       "2            1.0      964.0  \n",
       "3            1.0     1689.0  \n",
       "4            1.0     1541.0  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## The most important features for model are:\n",
    "\n",
    "X_train1.iloc[:, [16, 1, 169, 157, 10, 244, 9]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 15359.81144317209\n",
      "Root Mean Squared Error: 0.1241015844976499\n",
      "Root Mean Squared Error: 27368.303622670966\n"
     ]
    }
   ],
   "source": [
    "# Get predictions\n",
    "predictions_2 = my_model_2.predict(X_valid1)\n",
    "\n",
    "mae_2 = mean_absolute_error(y_valid, predictions_2)\n",
    "print(\"Mean Absolute Error:\" , mae_2)\n",
    "\n",
    "y_valid = np.array(y_valid)\n",
    "# base = 2.5611\n",
    "# # base = 2.494\n",
    "# rmse = np.sqrt(mean_squared_error((np.log(predictions_2)/np.log(base)), (np.log(y_valid)/np.log(base))))\n",
    "# rmse = np.sqrt(mean_squared_error(predictions_2, y_valid))\n",
    "rmse = np.sqrt(mean_squared_error(np.log(predictions_2), np.log(y_valid)))\n",
    "print(\"Root Mean Squared Error:\" , rmse)\n",
    "\n",
    "rmse2 = np.sqrt(mean_squared_error(predictions_2, y_valid))\n",
    "print(\"Root Mean Squared Error:\" , rmse2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SCORE2 = 0.13064 n_estimators = 450, learning_rate= 0.04, subsample = 0.5, max_depth = 5, colsample_bytree=0.8 + with droping vars\n",
    "#    Mean Absolute Error: 15166.343161386987, Mean Squared Error: 27821.293682309726 \n",
    "\n",
    "## + top2 SCORE = 14109.95424, SCORE2 = 0.12572  n_estimators = 450, learning_rate= 0.04, subsample = 0.5, max_depth = 5, colsample_bytree=0.8 + with dropping \n",
    "# except '3SsnPorch' (+)   Mean Absolute Error: 15142.2001953125; Mean Squared Error: 29109.281997806498\n",
    "\n",
    "## - ?? the same model (previous) but with simple imputer align with median\n",
    "# SCORE2 = 0.13415, Mean Absolute Error: 15094.940723994006, Root Mean Squared Error: 27935.43693200561\n",
    "\n",
    "## - ?? the same model (previous) with pipeline and align\n",
    "# SCORE2 = 0.13217 Mean Absolute Error: 15402.944162029109, Root Mean Squared Error: 28921.112689032045\n",
    "\n",
    "## 0.1339 n_estimators = 450, learning_rate= 0.06, colsample_bytree = 0.81, subsample = 0.8, max_depth = 4 + with dropping \n",
    "# except '3SsnPorch' (+)   Mean Absolute Error: 15089.681145654966   Mean Squared Error: 30960.239737581527\n",
    "\n",
    "## 0.1324   n_estimators = 450, learning_rate= 0.06, colsample_bytree = 0.8, subsample = 0.8, max_depth = 4 + with dropping \n",
    "# except '3SsnPorch' (+)   Mean Absolute Error: 14931.222977311643   Mean Squared Error: 29922.90346737125\n",
    "\n",
    "## 0.1313  n_estimators = 450, learning_rate= 0.065, colsample_bytree = 0.8, subsample = 0.8, max_depth = 4 + with dropping \n",
    "# except '3SsnPorch' (+)   Mean Absolute Error: 14836.028119648972      Mean Squared Error: 30055.96683219649\n",
    "\n",
    "## '+ top SCORE - 13997 SCORE2 - 0.13025 n_estimators = 450, learning_rate= 0.065, colsample_bytree = 0.8, subsample = 0.8, max_depth = 4, \n",
    "# reg_lambda = 0.998 + with dropping except '3SsnPorch' (+)\n",
    "# Mean Absolute Error: 14757.579757063357     Mean Squared Error: 29908.293379567116\n",
    "\n",
    "## '-' SCORE 14257 SCORE2 = 0.12945 0.1349 n_estimators = 450, learning_rate= 0.065, colsample_bytree = 0.8, subsample = 0.8, max_depth = 4, \n",
    "# reg_lambda = 0.998, min_child_weight = 3  + with dropping except '3SsnPorch' (+)\n",
    "# Mean Absolute Error: 14884.822412778254    Mean Squared Error: 27713.851497170308\n",
    "\n",
    "## '-' не улучшилось на 2м соревновании(можно попробовать, лучше чем предыущий максимальный скор)\n",
    "## SCORE2 = 0.13040    n_estimators = 550, learning_rate= 0.065, colsample_bytree = 0.8, subsample = 0.8, max_depth = 4, \n",
    "# reg_lambda = 0.998 + with dropping except '3SsnPorch' (+)\n",
    "# Mean Absolute Error: 14746.396002782534   Mean Squared Error: 29832.86481735542"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SCORE 14045 with dropping all wars and without limitation of objects\n",
    "# n_estimators = 900, learning_rate= 0.04, subsample = 0.8 (MAE 15265, RMSE 30160)\n",
    "\n",
    "## SCORE 14099 without dropping vars \n",
    "# n_estimators = 900, learning_rate= 0.04, subsample = 0.8 (MAE 15377, RMSE 30982)\n",
    "\n",
    "## SCORE 14257 n_estimators = 450, learning_rate= 0.065, colsample_bytree = 0.8, subsample = 0.8, max_depth = 4, \n",
    "# reg_lambda = 0.998, min_child_weight = 3 (MAE 14884, RMSE 27713)\n",
    "\n",
    "## SCORE 13997 n_estimators = 450, learning_rate= 0.065, colsample_bytree = 0.8, subsample = 0.8, max_depth = 4, \n",
    "# reg_lambda = 0.998 (MAE 14757, RMSE 29908)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RESULTS\n",
    "\n",
    "preds_test = my_model_2.predict(X_test1)\n",
    "output = pd.DataFrame({'Id': X_test.index,\n",
    "                       'SalePrice': preds_test})\n",
    "output.to_csv('submissionNastya23.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
