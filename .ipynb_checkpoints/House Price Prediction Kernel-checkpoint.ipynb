{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = pd.read_csv('https://storage.googleapis.com/kaggle-competitions-data/kaggle/10211/train.csv?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1561901199&Signature=Tok2i%2Fddx3XDpkbe%2FHOcxxVSAqGPMYC%2B1IJZMzuO6yH4BFQDUFe5zk9daZ0iQPJXBdg4TodP4eV9Z2Ycu3cPCJ%2FmGXjYlZDBwwRSZOh9oprBi4CKR5EavLNgk7BZ7Z6PgTxaPOcm3nGA6PzoFR1wI0rZOZPgl5rADNo3CVvjomaL9VK%2BQF9PCk6wsKNplnov6xbPGIiO9ZD89TCtMEG%2F0s6jixCgNysCFnfpf2IBYA3fIKtUdPyyQxWoselztESRuKkAVp20gUgSZgYG5OZnLG9X1FnWHJlm2lr48wclflCsifWkXItOxv%2FA4UgeUhxVd2D75zweqMa5tmrE4JXLtQ%3D%3D', index_col='Id')\n",
    "# X_test_full = pd.read_csv('https://storage.googleapis.com/kaggle-competitions-data/kaggle/10211/test.csv?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1561901250&Signature=VV82UXmJARoOBlo4OZ4Cxag%2F9nFeOKvz2VCkISsDHvsjEkuun5FLDEPiIdBhLorM0yymalzb0cE%2FKrvQgTEHu0kWelUwmXHzso6AeyNYErmlKVrQll7G3ySY6ghWOsx6TGgY20XKPBj0hb%2FPtKMt4AqaErpKboQofb9PQgDusUoudonRXhosfr8i1VEXV9a3wLyVRuMxnIhKveStr0Y87oNO9UJOOLYfl9ZXYjP7RR2Doj1CWbYgMoC3cFdGbwlZatBKVE95VLL%2B3v80qYD4BRVt9%2FMuO929z%2FEychB7ZZeb%2Byc02zhriAGN1mBmNxy3rBdWv01nIxmy4tYM%2F5nQYQ%3D%3D', index_col='Id')\n",
    "X = pd.read_csv('D:\\\\Learning_IT\\\\Data_analyses-Kaggle\\\\Data_House_Pricing\\\\train.csv', index_col='Id')\n",
    "X_test_full = pd.read_csv('D:\\\\Learning_IT\\\\Data_analyses-Kaggle\\\\Data_House_Pricing\\\\test.csv', index_col='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating target value and rest of data in train data set\n",
    "y = X.SalePrice              \n",
    "X.drop(['SalePrice'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LotFrontage      259\n",
       "Alley           1369\n",
       "MasVnrType         8\n",
       "MasVnrArea         8\n",
       "BsmtQual          37\n",
       "BsmtCond          37\n",
       "BsmtExposure      38\n",
       "BsmtFinType1      37\n",
       "BsmtFinType2      38\n",
       "Electrical         1\n",
       "FireplaceQu      690\n",
       "GarageType        81\n",
       "GarageYrBlt       81\n",
       "GarageFinish      81\n",
       "GarageQual        81\n",
       "GarageCond        81\n",
       "PoolQC          1453\n",
       "Fence           1179\n",
       "MiscFeature     1406\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating number of NA in each column\n",
    "missing_val_count_by_column = (X.isnull().sum())\n",
    "missing_val_count_by_column[missing_val_count_by_column > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So, a lot of variables are missing in columns: Alley, PoolQC, Fence, MiscFeature (more than half) - \n",
    "# so I decided to exclude these vars from model prediction.\n",
    "# Also it was decided to drop \"Utilities\" variable, because it is almost constant (except 1 value, that test-set doesn't \n",
    "# include)\n",
    "X = X.drop(['Alley', 'PoolQC','Fence','MiscFeature', 'Utilities', 'FireplaceQu'], axis=1)\n",
    "X_test_full = X_test_full.drop(['Alley', 'PoolQC','Fence','MiscFeature', 'Utilities', 'FireplaceQu'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also want to leave columns only with unique number of categorical variables less than 10, \n",
    "# so I decided to select categorical columns with relatively low cardinality\n",
    "\n",
    "categorical_cols = [cname for cname in X.columns if X[cname].dtype == \"object\"]\n",
    "# categorical_cols = [cname for cname in X.columns if X[cname].nunique() < 10 and \n",
    "#                         X[cname].dtype == \"object\"]\n",
    "numerical_cols = [cname for cname in X.columns if X[cname].dtype in ['int64', 'float64']]\n",
    "all_cols = categorical_cols + numerical_cols\n",
    "X_cor = X[all_cols].copy()\n",
    "X_test = X_test_full[all_cols].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HERE WILL START PART WITH PIPELINE AND OneHotEncoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break off validation set from training data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_cor, y, train_size=0.7, test_size=0.3,\n",
    "                                                               random_state=0)\n",
    "\n",
    "numerical_transformer = SimpleImputer(strategy='mean')\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "model = XGBRegressor(n_estimators = 900, learning_rate = 0.04, \n",
    "                     subsample = 0.8)\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('model', model)\n",
    "                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:50:54] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('preprocessor', ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "         transformer_weights=None,\n",
       "         transformers=[('num', SimpleImputer(copy=True, fill_value=None, missing_values=nan, strategy='mean',\n",
       "       verbose=0), ['MSSubClass', 'LotFrontage', 'LotArea', ...ha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=None, subsample=0.8, verbosity=1))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:51:08] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:51:19] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:51:31] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:51:47] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:51:57] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8671408519990905"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(clf, X_train, y_train, cv = 5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 15463.418539526256\n"
     ]
    }
   ],
   "source": [
    "preds11 = clf.predict(X_valid)\n",
    "\n",
    "# # Evaluate the model\n",
    "score11 = mean_absolute_error(y_valid, preds11)\n",
    "print('MAE:', score11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HERE THIS PART WAS ENDED**\n",
    "\n",
    "**HERE START PART WITH MANUAL PREPROCESSING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cor = pd.get_dummies(X_cor)\n",
    "X_test = pd.get_dummies(X_test)\n",
    "\n",
    "si = SimpleImputer(strategy='mean')\n",
    "\n",
    "X_cor_ed = pd.DataFrame(si.fit_transform(X_cor))\n",
    "X_cor_ed.columns = X_cor.columns\n",
    "\n",
    "X_test_ed = pd.DataFrame(si.fit_transform(X_test))\n",
    "X_test_ed.columns = X_test.columns\n",
    "X_test_ed.index = X_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Condition2_RRAe', 'Condition2_RRAn', 'Condition2_RRNn',\n",
       "       'Electrical_Mix', 'Exterior1st_ImStucc', 'Exterior1st_Stone',\n",
       "       'Exterior2nd_Other', 'GarageQual_Ex', 'Heating_Floor', 'Heating_OthW',\n",
       "       'HouseStyle_2.5Fin', 'RoofMatl_ClyTile', 'RoofMatl_Membran',\n",
       "       'RoofMatl_Metal', 'RoofMatl_Roll'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cols = X_cor_ed.columns\n",
    "test_cols = X_test_ed.columns\n",
    "common_cols = train_cols.intersection(test_cols)\n",
    "train_not_test = train_cols.difference(test_cols)\n",
    "train_not_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So now we will take columns that are in common between train and test datasets.\n",
    "X_cor_ed = X_cor_ed.drop(train_not_test, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break off validation set from training data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_cor_ed, y, train_size=0.7, test_size=0.3,\n",
    "                                                               random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:52:08] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "       importance_type='gain', learning_rate=0.04, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=900,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=None, subsample=0.8, verbosity=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb = XGBRegressor(n_estimators = 900, learning_rate = 0.04, \n",
    "                     subsample = 0.8)\n",
    "\n",
    "model_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:52:46] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:53:21] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:53:53] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:54:25] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:54:56] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.867370700336313"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(model_xgb, X_train, y_train, cv = 5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 15023.990341395547\n"
     ]
    }
   ],
   "source": [
    "preds = model_xgb.predict(X_valid)\n",
    "\n",
    "# # Evaluate the model\n",
    "score = mean_absolute_error(y_valid, preds)\n",
    "print('MAE:', score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Writing output to file\n",
    "\n",
    "preds_out = model_xgb.predict(X_test_ed)\n",
    "output = pd.DataFrame({'Id': X_test_ed.index,\n",
    "                       'SalePrice': preds_out})\n",
    "\n",
    "output.to_csv('submission_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESULTS:\n",
    "\n",
    "# n_estimators=800, max_depth=4, learning_rate=0.05, - MAE 16492.056493471748\n",
    "# n_estimators = 900, learning_rate = 0.04, max_depth = 4, reg_alpha = 1, reg_lambda = 1, subsample = 0.5\n",
    "#                                        - MAE MAE: 15750.379468107876\n",
    "# n_estimators = 900, learning_rate = 0.04, subsample = 0.8 - MAE: 15617.851789918665\n",
    "\n",
    "# imputer mean: model n_estimators = 900, learning_rate = 0.04, subsample = 0.8 - MAE: 15036.240002497147\n",
    " \n",
    "# pipeline with imputer mean for num, delete FireplaceQu, without limitation for categoric variables + \n",
    "#  + XGB n_estimators = 900, learning_rate = 0.04, subsample = 0.8 - MAE: 15023.990341395547\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2-ND MODEL RANDOM FOREST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=5,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=4,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=400, n_jobs=None,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf = RandomForestRegressor(criterion = 'mse', max_depth = 5, min_samples_split = 4, n_estimators = 400)\n",
    "model_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8246474002773507"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(model_rf, X_train, y_train, cv = 5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 19669.5457386117\n"
     ]
    }
   ],
   "source": [
    "preds_rf = model_rf.predict(X_valid)\n",
    "\n",
    "# # Evaluate the model\n",
    "score2 = mean_absolute_error(y_valid, preds_rf)\n",
    "print('MAE:', score2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Writing output to file\n",
    "\n",
    "preds_out = model_rf.predict(X_test_ed)\n",
    "output = pd.DataFrame({'Id': X_test_ed.index,\n",
    "                       'SalePrice': preds_out})\n",
    "\n",
    "output.to_csv('submission_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
