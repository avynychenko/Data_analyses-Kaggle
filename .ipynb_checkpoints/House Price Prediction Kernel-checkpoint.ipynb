{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import Lasso\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('/Users/avyny/Documents/Data_analyses-Kaggle/Data_House_Pricing/train.csv', index_col='Id')\n",
    "X_test_full = pd.read_csv('/Users/avyny/Documents/Data_analyses-Kaggle/Data_House_Pricing/test.csv', index_col='Id')\n",
    "# X = pd.read_csv('D:\\\\Learning_IT\\\\Data_analyses-Kaggle\\\\Data_House_Pricing\\\\train.csv', index_col='Id')\n",
    "# X_test_full = pd.read_csv('D:\\\\Learning_IT\\\\Data_analyses-Kaggle\\\\Data_House_Pricing\\\\test.csv', index_col='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating target value and rest of data in train data set\n",
    "y = X.SalePrice              \n",
    "X.drop(['SalePrice'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LotFrontage      259\n",
       "Alley           1369\n",
       "MasVnrType         8\n",
       "MasVnrArea         8\n",
       "BsmtQual          37\n",
       "BsmtCond          37\n",
       "BsmtExposure      38\n",
       "BsmtFinType1      37\n",
       "BsmtFinType2      38\n",
       "Electrical         1\n",
       "FireplaceQu      690\n",
       "GarageType        81\n",
       "GarageYrBlt       81\n",
       "GarageFinish      81\n",
       "GarageQual        81\n",
       "GarageCond        81\n",
       "PoolQC          1453\n",
       "Fence           1179\n",
       "MiscFeature     1406\n",
       "dtype: int64"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating number of NA in each column\n",
    "missing_val_count_by_column = (X.isnull().sum())\n",
    "missing_val_count_by_column[missing_val_count_by_column > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So, a lot of variables are missing in columns: Alley, PoolQC, Fence, MiscFeature (more than half) - \n",
    "# so I decided to exclude these vars from model prediction.\n",
    "# Also it was decided to drop \"Utilities\" variable, because it is almost constant (except 1 value, that test-set doesn't \n",
    "# include)\n",
    "\n",
    "# 'TotalBsmtSF' is sum of 'BsmtUnfSF' + 'BsmtFinSF2' + 'BsmtFinSF1'\n",
    "# ???? TotRmsAbvGrd\n",
    "\n",
    "'Alley', 'PoolQC','Fence','MiscFeature', 'Utilities', 'Street', 'PoolArea', 'MiscVal'\n",
    "X = X.drop(['Alley', 'PoolQC','Fence','MiscFeature', 'Utilities', 'Street', 'PoolArea', 'MiscVal', 'TotalBsmtSF', '3SsnPorch'], axis=1)\n",
    "X_test_full = X_test_full.drop(['Alley', 'PoolQC','Fence','MiscFeature', 'Utilities', 'Street', 'PoolArea', 'MiscVal', 'TotalBsmtSF', '3SsnPorch'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also want to leave columns only with unique number of categorical variables less than 10, \n",
    "# so I decided to select categorical columns with relatively low cardinality\n",
    "\n",
    "categorical_cols = [cname for cname in X.columns if X[cname].dtype == \"object\"]\n",
    "# categorical_cols = [cname for cname in X.columns if X[cname].nunique() < 10 and \n",
    "#                         X[cname].dtype == \"object\"]\n",
    "numerical_median = ['OverallCond', 'OverallQual', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2',\n",
    "                   'BsmtUnfSF', 'LowQualFinSF', 'GrLivArea', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr',\n",
    "                   'TotRmsAbvGrd', 'GarageYrBlt', 'GarageCars', 'EnclosedPorch', 'ScreenPorch', 'MoSold', 'YrSold']\n",
    "\n",
    "numerical_mean = ['LotFrontage', 'LotArea', '1stFlrSF', '2ndFlrSF', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF']\n",
    "\n",
    "numerical_frequent = ['MSSubClass', 'BsmtFullBath', 'BsmtHalfBath', 'Fireplaces']\n",
    "\n",
    "all_cols = categorical_cols + numerical_median + numerical_mean + numerical_frequent\n",
    "X_cor = X[all_cols].copy()\n",
    "X_test = X_test_full[all_cols].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HERE WILL START PART WITH PIPELINE AND OneHotEncoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break off validation set from training data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_cor, y, train_size=0.8, test_size=0.2,\n",
    "                                                               random_state=0)\n",
    "\n",
    "numerical_transformer_mean = SimpleImputer(strategy='mean')\n",
    "numerical_transformer_median = SimpleImputer(strategy='median')\n",
    "numerical_transformer_freq = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num1', numerical_transformer_mean, numerical_mean),\n",
    "        ('num2', numerical_transformer_median, numerical_median),\n",
    "        ('num3', numerical_transformer_freq, numerical_frequent),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "model = XGBRegressor(colsample_bytree = 0.7, learning_rate=0.03, max_depth=6, n_estimators=850)\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('model', model)\n",
    "                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ! Grid Search for Pipeline\n",
    "\n",
    "# parameters = dict(model__max_depth = [3, 4, 5], \n",
    "#                   model__learning_rate = [0.01, 0.03, 0.04, 0.05, 0.06],\n",
    "#                   model__n_estimators = [100, 300, 400, 450, 550, 650],\n",
    "#                   model__colsample_bytree = [0.7, 0.8, 1]\n",
    "#                  )\n",
    "# cv = GridSearchCV(clf, param_grid=parameters)\n",
    "\n",
    "# cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:44:31] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocessor',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('num1',\n",
       "                                                  SimpleImputer(add_indicator=False,\n",
       "                                                                copy=True,\n",
       "                                                                fill_value=None,\n",
       "                                                                missing_values=nan,\n",
       "                                                                strategy='mean',\n",
       "                                                                verbose=0),\n",
       "                                                  ['LotFrontage', 'LotArea',\n",
       "                                                   '1stFlrSF', '2ndFlrSF',\n",
       "                                                   'GarageArea', 'WoodDeckSF',\n",
       "                                                   'OpenPorchSF...\n",
       "                              colsample_bylevel=1, colsample_bynode=1,\n",
       "                              colsample_bytree=0.7, gamma=0,\n",
       "                              importance_type='gain', learning_rate=0.03,\n",
       "                              max_delta_step=0, max_depth=6, min_child_weight=1,\n",
       "                              missing=None, n_estimators=850, n_jobs=1,\n",
       "                              nthread=None, objective='reg:linear',\n",
       "                              random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "                              scale_pos_weight=1, seed=None, silent=None,\n",
       "                              subsample=1, verbosity=1))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 15570.23527129709\n",
      "RMSE: 29632.487944218585\n",
      "Root Mean Squared Error: 0.12486422381380102\n"
     ]
    }
   ],
   "source": [
    "preds11 = clf.predict(X_valid)\n",
    "\n",
    "# # Evaluate the model\n",
    "score11 = mean_absolute_error(y_valid, preds11)\n",
    "print('MAE:', score11)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_valid, preds11))\n",
    "print('RMSE:', rmse)\n",
    "\n",
    "rmse2 = np.sqrt(mean_squared_error(np.log(preds11), np.log(y_valid)))\n",
    "print(\"Root Mean Squared Error:\" , rmse2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_val_score(clf, X_train, y_train, cv = 5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HERE THIS PART WAS ENDED**\n",
    "\n",
    "**HERE START PART WITH MANUAL PREPROCESSING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cor = pd.get_dummies(X_cor)\n",
    "X_test = pd.get_dummies(X_test)\n",
    "\n",
    "si = SimpleImputer(strategy='mean')\n",
    "\n",
    "X_cor_ed = pd.DataFrame(si.fit_transform(X_cor))\n",
    "X_cor_ed.columns = X_cor.columns\n",
    "\n",
    "X_test_ed = pd.DataFrame(si.fit_transform(X_test))\n",
    "X_test_ed.columns = X_test.columns\n",
    "X_test_ed.index = X_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Condition2_RRAe', 'Condition2_RRAn', 'Condition2_RRNn',\n",
       "       'Electrical_Mix', 'Exterior1st_ImStucc', 'Exterior1st_Stone',\n",
       "       'Exterior2nd_Other', 'GarageQual_Ex', 'Heating_Floor', 'Heating_OthW',\n",
       "       'HouseStyle_2.5Fin', 'RoofMatl_ClyTile', 'RoofMatl_Membran',\n",
       "       'RoofMatl_Metal', 'RoofMatl_Roll'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cols = X_cor_ed.columns\n",
    "test_cols = X_test_ed.columns\n",
    "common_cols = train_cols.intersection(test_cols)\n",
    "train_not_test = train_cols.difference(test_cols)\n",
    "train_not_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So now we will take columns that are in common between train and test datasets.\n",
    "X_cor_ed = X_cor_ed.drop(train_not_test, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break off validation set from training data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_cor_ed, y, train_size=0.8, test_size=0.2,\n",
    "                                                               random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:46:16] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=0.7, gamma=0,\n",
       "             importance_type='gain', learning_rate=0.03, max_delta_step=0,\n",
       "             max_depth=6, min_child_weight=1, missing=None, n_estimators=850,\n",
       "             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "             silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb = XGBRegressor(colsample_bytree = 0.7, learning_rate=0.03, max_depth=6, n_estimators=850)\n",
    "\n",
    "model_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 16205.5849609375\n",
      "RMSE: 27940.01413820555\n",
      "Root Mean Squared Error: 0.12718326053139634\n"
     ]
    }
   ],
   "source": [
    "preds = model_xgb.predict(X_valid)\n",
    "\n",
    "# # Evaluate the model\n",
    "score = mean_absolute_error(y_valid, preds)\n",
    "print('MAE:', score)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_valid, preds))\n",
    "print('RMSE:', rmse)\n",
    "\n",
    "rmse2 = np.sqrt(mean_squared_error(np.log(preds), np.log(y_valid)))\n",
    "print(\"Root Mean Squared Error:\" , rmse2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_val_score(model_xgb, X_train, y_train, cv = 5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Writing output to file\n",
    "\n",
    "preds_out = model_xgb.predict(X_test_ed)\n",
    "output = pd.DataFrame({'Id': X_test_ed.index,\n",
    "                       'SalePrice': preds_out})\n",
    "\n",
    "output.to_csv('submission_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESULTS:\n",
    "\n",
    "# n_estimators=800, max_depth=4, learning_rate=0.05, - MAE 16492.056493471748\n",
    "# n_estimators = 900, learning_rate = 0.04, max_depth = 4, reg_alpha = 1, reg_lambda = 1, subsample = 0.5\n",
    "#                                        - MAE MAE: 15750.379468107876\n",
    "# n_estimators = 900, learning_rate = 0.04, subsample = 0.8 - MAE: 15617.851789918665\n",
    "\n",
    "# imputer mean: model n_estimators = 900, learning_rate = 0.04, subsample = 0.8 - MAE: 15036.240002497147\n",
    " \n",
    "# pipeline with imputer mean for num, delete FireplaceQu, without limitation for categoric variables + \n",
    "#  + XGB n_estimators = 900, learning_rate = 0.04, subsample = 0.8 - MAE: 15023.990341395547\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**END OF XGBOOST**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2-ND MODEL RANDOM FOREST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=5,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=4,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=400,\n",
       "                      n_jobs=None, oob_score=False, random_state=None,\n",
       "                      verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf = RandomForestRegressor(criterion = 'mse', max_depth = 5, min_samples_split = 4, n_estimators = 400)\n",
    "model_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_val_score(model_rf, X_train, y_train, cv = 5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 20034.07882477593\n",
      "Root Mean Squared Error: 0.15706657559926132\n"
     ]
    }
   ],
   "source": [
    "preds_rf = model_rf.predict(X_valid)\n",
    "\n",
    "# # Evaluate the model\n",
    "score2 = mean_absolute_error(y_valid, preds_rf)\n",
    "print('MAE:', score2)\n",
    "\n",
    "rmse2 = np.sqrt(mean_squared_error(np.log(preds_rf), np.log(y_valid)))\n",
    "print(\"Root Mean Squared Error:\" , rmse2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Writing output to file\n",
    "\n",
    "preds_out = model_rf.predict(X_test_ed)\n",
    "output = pd.DataFrame({'Id': X_test_ed.index,\n",
    "                       'SalePrice': preds_out})\n",
    "\n",
    "output.to_csv('submission_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
